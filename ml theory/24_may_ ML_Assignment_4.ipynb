{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 What is clustering in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clustering is an unsupervised learning technique that groups a set of data points into clusters based on similarity. The goal is to ensure that data points within the same cluster are more similar to each other than to those in different clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Explain the difference between supervised and unsupervised clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clustering is inherently an unsupervised task, so supervised clustering typically doesn't exist. However, in a supervised context, clustering may involve labeled data to evaluate cluster quality, whereas unsupervised clustering relies purely on data patterns without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 What are the key applications of clustering algorithms7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Market segmentation\n",
    "- Image compression\n",
    "- Document categorization\n",
    "- Anomaly detection\n",
    "- Customer segmentation\n",
    "- Social network analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 Describe the K-means clustering algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-means clustering partitions data into KK clusters by minimizing the variance within each cluster. It starts by initializing KK centroids, assigns points to the nearest centroid, and updates centroids iteratively until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 What are the main advantages and disadvantages of K-means clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Advantages:\n",
    "\n",
    "    - Easy to implement\n",
    "    - Scalable to large datasets\n",
    "    - Efficient with linear time complexity\n",
    "\n",
    "* Disadvantages:\n",
    "\n",
    "    - Sensitive to the choice of KK\n",
    "    - Prone to converging to local minima\n",
    "    - Affected by outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6  How does hierarchical clustering work7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hierarchical clustering builds a hierarchy of clusters by either:\n",
    "\n",
    "   -  Agglomerative approach: Starting with each data point as an individual cluster and merging them.\n",
    "   -  Divisive approach: Starting with one cluster and recursively splitting it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 What are the different linkage criteria used in hierarchical clustering7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Single linkage: Minimum distance between points in clusters.\n",
    "* Complete linkage: Maximum distance between points in clusters.\n",
    "* Average linkage: Average distance between all points in clusters.\n",
    "* Ward’s linkage: Minimizes the variance within clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 Explain the concept of DBSCAN clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Density-Based Spatial Clustering of Applications with Noise (DBSCAN) identifies clusters as dense regions in space separated by regions of lower density. It does not require specifying the number of clusters and can handle noise and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 What are the parameters involved in DBSCAN clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Epsilon (ε): The maximum distance between two points to be considered neighbors.\n",
    "* MinPts: The minimum number of points required to form a dense region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10 Describe the process of evaluating clustering algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Internal metrics: Silhouette score, Davies-Bouldin Index.\n",
    "* External metrics: Adjusted Rand Index, Mutual Information.\n",
    "* Visualization techniques: Dendrograms, cluster scatter plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11 What is the silhouette score, and how is it calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The silhouette score measures how similar a data point is to its cluster compared to other clusters. It ranges from -1 to 1, where a high value indicates well-separated clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12  Discuss the challenges of clustering high-dimensional data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Curse of dimensionality: In high dimensions, data points become equidistant, making clustering less effective.\n",
    "* Scalability: High-dimensional data increases computational cost.\n",
    "* Visualization: Clusters are harder to visualize and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13 Explain the concept of density-based clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Density-based clustering groups data points that are closely packed together, with areas of low density separating different clusters. DBSCAN is a popular algorithm that follows this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14 How does Gaussian Mixture Model (GMM) clustering differ from K-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GMM assumes that data points are generated from a mixture of several Gaussian distributions, whereas K-means assumes spherical clusters with uniform variance. GMM is more flexible as it allows for elliptical clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q15 What are the limitations of traditional clustering algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Traditional algorithms struggle with non-spherical clusters, high-dimensional data, overlapping clusters, and are sensitive to noise and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16 Discuss the applications of spectral clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spectral clustering is used in image segmentation, social network analysis, and identifying community structures in graphs. It works well with complex cluster structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17 Explain the concept of affinity propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Affinity propagation is a clustering method where data points exchange messages about potential exemplars, leading to clusters forming around exemplars without needing a predefined number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18 How do you handle categorical variables in clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical variables can be handled using techniques like one-hot encoding, creating a similarity matrix, or using algorithms like k-modes that are designed for categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q19 Describe the elbow method for determining the optimal number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The elbow method plots the within-cluster sum of squares against the number of clusters and looks for an \"elbow\" point where the rate of decrease slows, indicating the optimal number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q20 What are some emerging trends in clustering research?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trends include deep clustering (combining deep learning with clustering), clustering in streaming data, and clustering in dynamic environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q21 What is anomaly detection, and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Anomaly detection identifies unusual patterns that don't conform to expected behavior. It's critical in fraud detection, network security, and health monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q22 Discuss the types of anomalies encountered in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Types of anomalies include point anomalies (single instances), contextual anomalies (anomalous in a specific context), and collective anomalies (anomalous patterns over multiple instances)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q23 Explain the difference between supervised and unsupervised anomaly detection techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised techniques use labeled data for training, while unsupervised techniques detect anomalies without labeled data, typically by identifying data points that deviate from the norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q24 Describe the Isolation Forest algorithm for anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Isolation Forest algorithm isolates anomalies by recursively partitioning the data. Anomalies are isolated quicker due to their distinct characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q25 How does One-Class SVM work in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One-Class SVM finds a boundary around normal data points and labels anything outside the boundary as an anomaly. It works well in scenarios where only normal data is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q26 Discuss the challenges of anomaly detection in high-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* High-dimensional data suffers from the curse of dimensionality, making it difficult to identify meaningful anomalies as all points can appear equidistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q27 Explain the concept of novelty detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Novelty detection focuses on identifying new, unseen patterns that differ from normal data, which can occur in a system after a model has been trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q28 What are some real-world applications of anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Applications include fraud detection, network security, fault detection in machinery, and healthcare monitoring for abnormal patient behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q29 Describe the Local Outlier Factor (LOF) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LOF measures the local density deviation of a data point compared to its neighbors, identifying outliers based on the degree of isolation from its surrounding points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q30 How do you evaluate the performance of an anomaly detection model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Performance is evaluated using metrics like precision, recall, F1-score, and ROC-AUC, depending on the balance between false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q31 Discuss the role of feature engineering in anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feature engineering enhances model performance by transforming raw data into more meaningful representations, improving the model's ability to detect anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q32  What are the limitations of traditional anomaly detection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Traditional methods often assume static data distributions, struggle with high-dimensional data, and may not generalize well to evolving or complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q33 Explain the concept of ensemble methods in anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ensemble methods combine multiple anomaly detection models to improve robustness and accuracy by aggregating diverse decisions from different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q34 How does autoencoder-based anomaly detection work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An autoencoder learns to compress and reconstruct normal data. Anomalies, which fail to reconstruct well, have higher reconstruction errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q35 What are some approaches for handling imbalanced data in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Techniques include oversampling the minority class, undersampling the majority class, or using anomaly detection algorithms specifically designed to handle imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q36 Describe the concept of semi-supervised anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Semi-supervised anomaly detection uses a small amount of labeled normal data to build models that detect anomalies in largely unlabeled datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q37 Discuss the trade-offs between false positives and false negatives in anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* False positives waste resources, while false negatives can result in undetected anomalies with potentially serious consequences. The balance depends on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q38 How do you interpret the results of an anomaly detection model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interpretation involves understanding the model's output, analyzing false positives and false negatives, and assessing whether the detected anomalies are meaningful in the application context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q39 What are some open research challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Challenges include detecting anomalies in evolving data streams, handling high-dimensional and noisy data, and improving scalability and real-time performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q40 Explain the concept of contextual anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Contextual anomaly detection identifies anomalies based on the specific context, such as time or location, where a data point that is normal in one context may be anomalous in another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q41 What is time series analysis, and what are its key components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time series analysis focuses on data points collected over time, with key components like trend, seasonality, and noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q42 Discuss the difference between univariate and multivariate time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Univariate analysis examines a single time-dependent variable, while multivariate analysis studies multiple variables and their interrelationships over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q43 Describe the process of time series decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decomposition involves breaking down a time series into its constituent components: trend, seasonality, and residual (noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q44 What are the main components of a time series decomposition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The main components are trend (long-term direction), seasonality (regular fluctuations), and residual (random noise or irregularities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q45 Explain the concept of stationarity in time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A time series is stationary if its statistical properties, such as mean and variance, are constant over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q46 How do you test for stationarity in a time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tests like the Augmented Dickey-Fuller (ADF) test and the KPSS test can check for stationarity by analyzing the time series' properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q47 Discuss the autoregressive integrated moving average (ARIMA) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ARIMA models time series data using three components: autoregression (AR), differencing (I), and moving average (MA), capturing various patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q48 What are the parameters of the ARIMA model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ARIMA has three parameters: p (autoregressive order), d (degree of differencing), and q (moving average order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q49 Describe the seasonal autoregressive integrated moving average (SARIMA) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SARIMA extends ARIMA to handle seasonality by including seasonal AR, differencing, and MA terms, along with a seasonal period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q50 How do you choose the appropriate lag order in an ARIMA model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The appropriate lag order is chosen using information criteria like AIC or BIC, or by analyzing autocorrelation and partial autocorrelation functions (ACF and PACF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q51 Explain the concept of differencing in time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Differencing is used to transform a non-stationary time series into a stationary one by subtracting consecutive observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q52 What is the Box-Jenkins methodology?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Box-Jenkins methodology is a systematic approach to identifying, estimating, and checking ARIMA models for time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q53 Discuss the role of ACF and PACF plots in identifying ARIMA parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ACF plots help identify the q parameter, while PACF plots help identify the p parameter by showing autocorrelations and partial autocorrelations, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q54 How do you handle missing values in time series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Methods include interpolation, forward/backward filling, or using models like Kalman filters to estimate the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q55 Describe the concept of exponential smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exponential smoothing is a time series forecasting technique that applies exponentially decreasing weights to past observations. It gives more importance to recent data points while still considering older data. The method can be applied in three forms: single (for data with no trend or seasonality), double (for data with a trend), and triple (for data with both trend and seasonality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q56 What is the Holt-Winters method, and when is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Holt-Winters method is an extension of exponential smoothing, which includes components for both trend and seasonality. It is used when the data exhibits both a linear trend and seasonal patterns. It can be divided into:\n",
    "\n",
    "    - Additive model: used when the seasonal variations are roughly constant over time.\n",
    "    - Multiplicative model: used when the seasonal variations increase or decrease proportionally to the level of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q57 Discuss the challenges of forecasting long-term trends in time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Long-term trend forecasting is challenging due to factors like:\n",
    "\n",
    "    - Structural changes: Sudden shifts in data patterns due to external factors (e.g., policy changes, market shifts) make predictions harder.\n",
    "    - Seasonal and cyclical variations: Long-term trends are often obscured by seasonality or cyclic behavior.\n",
    "    - Uncertainty and external events: The further into the future you forecast, the more external factors (economic changes, natural disasters) can impact predictions.\n",
    "    - Model overfitting: Complex models may capture noise rather than the true long-term trend, leading to poor performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q58 Explain the concept of seasonality in time series analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seasonality refers to regular and predictable patterns that repeat over a fixed period, such as daily, monthly, or yearly cycles. In time series analysis, it's essential to identify and account for these seasonal patterns to improve the accuracy of forecasts. For example, sales may increase every December due to the holiday season, which is a seasonal effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q59 How do you evaluate the performance of a time series forecasting model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time series models are evaluated using various metrics, including:\n",
    "\n",
    "   -  Mean Absolute Error (MAE): Measures the average magnitude of errors in a set of predictions.\n",
    "   -  Root Mean Squared Error (RMSE): Emphasizes larger errors by squaring the differences before averaging them.\n",
    "   -  Mean Absolute Percentage Error (MAPE): Expresses errors as a percentage, making it easy to interpret.\n",
    "   -  R-squared: Measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q60 What are some advanced techniques for time series forecasting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Advanced techniques include:\n",
    "\n",
    "   -  ARIMA/SARIMA: These models extend autoregressive approaches to handle seasonal data and incorporate both autoregression and moving average elements.\n",
    "   - Long Short-Term Memory (LSTM): A type of recurrent neural network (RNN) designed for sequence prediction, effective in capturing long-term dependencies in time series data.\n",
    "   - Prophet: Developed by Facebook, this tool handles missing data, trends, and seasonality, and is robust to outliers.\n",
    "   - Exponential Smoothing State Space Model (ETS): Extends exponential smoothing models by combining trend and seasonal components using state space models.\n",
    "   - Ensemble methods: Combining predictions from multiple models to improve robustness and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
